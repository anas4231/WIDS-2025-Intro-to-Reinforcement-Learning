{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Bandit Problem"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "# imports\n",
                "from bandits import Bandit\n",
                "import random\n",
                "# Include your imports here, if any are used. ",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "A bandit is one option (or “arm”) you can choose, where the reward you get is uncertain and must be learned by trying it out.\n",
                "In multi-armed bandits, you repeatedly pick among several such uncertain options to find which one pays best."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "A list of ten bandit objects initialized in the list..."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "bandits = [Bandit(random.random()*4-2) for _ in range(10)]"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "To generate reward from that bandit, use the pullLever() command"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "0.04364432528747145"
                        ]
                    },
                    "execution_count": 3,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "bandits[0].pullLever()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Greedy algorithm Implementation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [],
            "source": [
                "def run_greedy():\n",
                "    # TODO: Implement the greedy algorithm here\n",
                "    # Return the reward from the bandits in a list\n",
                "    \n",
                " def run_greedy():\n",
                " n_arms = len(bandits)\n",
                " counts = [0] * n_arms\n",
                " values = [0.0] * n_arms\n",
                " rewards = []                                                                   \n",
                " for _ in range(1000):  # Number of iterations\n",
                "     # Choose arm with highest estimated value\n",
                "     chosen_arm = values.index(max(values))\n",
                "     reward = bandits[chosen_arm].pullLever()\n",
                "     counts[chosen_arm] += 1\n",
                "     values[chosen_arm] += (reward - values[chosen_arm]) / counts[chosen_arm]\n",
                "     rewards.append(reward)\n",
                " return rewards\n",
                "    pass"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Plot the cumulative average of rewards as the number of iterations increases. and display that image below.",
                "rewards = run_greedy()                                                    \n",
                "cumulative_avg = [sum(rewards[:i+1]) / (i+1) for i in range(len(rewards))]\n",
                "plt.plot(cumulative_avg, label='Greedy')\n",
                "plt.xlabel('Iterations')\n",
                "plt.ylabel('Cumulative Average Reward')\n",
                "plt.title('Greedy Algorithm')\n",
                "plt.legend()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## $\\epsilon$-greedy Algorithm"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [],
            "source": [
                "def run_epsilon_greedy(epsilon):\n",
                "    # TODO: Implement the epsilon greedy algorithm here\n",
                "    # Return the reward from the bandits in a list\n",
                "\n",
                "def run_epsilon_greedy(epsilon):                  \n",
                "n_arms = len(bandits)\n",
                "counts = [0] * n_arms\n",
                "values = [0.0] * n_arms\n",
                "rewards = []\n",
                "for _ in range(1000):\n",
                "    if random.random() < epsilon:\n",
                "        chosen_arm = random.randint(0, n_arms - 1)\n",
                "    else:\n",
                "        chosen_arm = values.index(max(values))\n",
                "    reward = bandits[chosen_arm].pullLever()\n",
                "    counts[chosen_arm] += 1\n",
                "    values[chosen_arm] += (reward - values[chosen_arm]) / counts[chosen_arm]\n",
                "    rewards.append(reward)\n",
                "return rewards\n",
                " pass"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Plot the cumulative average of rewards as the number of iterations increases but for various values of $\\epsilon$.",
                "          epsilon = 0.1  \n",
                "rewards = run_epsilon_greedy(epsilon)\n",
                "cumulative_avg = [sum(rewards[:i+1]) / (i+1) for i in range(len(rewards))]\n",
                "plt.plot(cumulative_avg, label=f'ε-Greedy (ε={epsilon})')\n",
                "plt.xlabel('Iterations')\n",
                "plt.ylabel('Cumulative Average Reward')\n",
                "plt.title('ε-Greedy Algorithm')\n",
                "plt.legend()\n",
                "plt.show()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Finding the optimal $\\epsilon$"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Run the $\\epsilon$-greedy algorithm for 1000 iterations and find the optimal $\\epsilon$ value by plotting the cumulative average of rewards for various values of $\\epsilon$"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Optimistic Initial Values"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [],
            "source": [
                "def run_optimistic_greedy():\n",
                "    # TODO: Implement the optimistic greedy algorithm here\n",
                "\n",
                "def run_optimistic_greedy():                                                  \n",
                "n_arms = len(bandits)\n",
                "counts = [0] * n_arms\n",
                "values = [10.0] * n_arms  # Optimistic initial value\n",
                "rewards = []\n",
                "for _ in range(1000):\n",
                "    chosen_arm = values.index(max(values))\n",
                "    reward = bandits[chosen_arm].pullLever()\n",
                "    counts[chosen_arm] += 1\n",
                "    values[chosen_arm] += (reward - values[chosen_arm]) / counts[chosen_arm]\n",
                "    rewards.append(reward)\n",
                "return rewards\n",
                "    # Return the reward from the bandits in a list\n",
                "    pass"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Plot the cumulative average of rewards as the number of iterations increases for an optimistic greedy of $Q_1 = 10$ and a non-optimistic $\\epsilon = 0.1$ and try to compare which is better.",
                "rewards = run_optimistic_greedy()\n",
                "cumulative_avg = [sum(rewards[:i+1]) / (i+1) for i in range(len(rewards))]\n",
                "plt.plot(cumulative_avg, label='Optimistic Greedy')\n",
                "plt.xlabel('Iterations')\n",
                "plt.ylabel('Cumulative Average Reward')\n",
                "plt.title('Optimistic Greedy Algorithm')\n",
                "plt.legend()\n",
                "plt.show()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Upper Confidence Bound (UCB)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [],
            "source": [
                "def run_ucb(c):\n",
                "    # TODO: Implement the UCB algorithm here\n",
                "    # Return the reward from the bandits in a list\n",
                " import math",
                "def run_ucb(c):                                                                                        \n",
                "    n_arms = len(bandits)\n",
                "    counts = [0] * n_arms\n",
                "    values = [0.0] * n_arms\n",
                "    rewards = []\n",
                "    total_steps = 0\n",
                "    for _ in range(1000):\n",
                "        ucb_values = []\n",
                "        for i in range(n_arms):\n",
                "            if counts[i] == 0:\n",
                "                ucb_values.append(float('inf'))\n",
                "            else:\n",
                "                ucb_values.append(values[i] + c * math.sqrt(math.log(total_steps + 1) / counts[i]))\n",
                "        chosen_arm = ucb_values.index(max(ucb_values))\n",
                "        reward = bandits[chosen_arm].pullLever()\n",
                "        counts[chosen_arm] += 1\n",
                "        values[chosen_arm] += (reward - values[chosen_arm]) / counts[chosen_arm]\n",
                "        total_steps += 1\n",
                "        rewards.append(reward)\n",
                "    return rewards\n",
                "    pass"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "c = 2\n",
                "rewards = run_ucb(c)\n",
                "cumulative_avg = [sum(rewards[:i+1]) / (i+1) for i in range(len(rewards))]\n",
                "plt.plot(cumulative_avg, label=f'UCB (c={c})')\n",
                "plt.xlabel('Iterations')\n",
                "plt.ylabel('Cumulative Average Reward')\n",
                "plt.title('UCB Algorithm')\n",
                "plt.legend()\n",
                "plt.show()\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.13.6"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
